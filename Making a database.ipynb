{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5019de54-eee4-4946-bca6-50cb71b98742",
   "metadata": {},
   "source": [
    "# Creating a database"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8de65563-181e-4979-acdb-41e15152118d",
   "metadata": {},
   "source": [
    "Here you will be creating the data that will go into your database. The data is created in python and will be turned into a database in SQLite."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "a847fdab-ef0e-4816-81d6-2fc92fec6b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import string\n",
    "from faker import Faker"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0f079fd-42ed-47b0-bdff-8bb2aedc42ca",
   "metadata": {},
   "source": [
    "We need to create data of various formats: nominal, ordinal, interval and ratio.\n",
    "Let's pick the topic of house sales."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b94999c1-d9a2-4a8c-ac3c-d02061be742f",
   "metadata": {},
   "source": [
    "That's a minimal example, now create some additional (at least 4 more) columns for any the following concepts:\n",
    "- Number of Bedrooms\n",
    "- Number of Bathrooms\n",
    "- Total Square Footage\n",
    "- Property Type (Detached, Semi-Detached, etc.)\n",
    "- Number of Floors\n",
    "- Furnishing (Finished, Unfinished)\n",
    "- Garden Size\n",
    "- Time on Market\n",
    "- Mortgage Rate\n",
    "- Number of Previous Owners\n",
    "- Pet-Friendly (Yes/No)\n",
    "- Appliances Included\n",
    "- Internet Connectivity (Fiber, DSL, etc.)\n",
    "- Local Crime Rate\n",
    "- Distance to Nearby Schools\n",
    "- Distance to Motorway\n",
    "- Name of Seller\n",
    "\n",
    "\n",
    "Random is better and make sure to ensure the numbers **make sense** and have a consistent N.\n",
    "Read the numpy random documentation for ideas on different distributions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "835140f7-2da0-4f5f-a149-d20822b2cf4c",
   "metadata": {},
   "source": [
    "Most real databases have missing data or otherwise undesirable values, \"filler\" values. You can simulate this with masking. Note that integers cannot have NaNs as options (so not np.random.randint)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38967981-01a4-438d-9673-1f79c73c691a",
   "metadata": {},
   "source": [
    "You should apply something similar to your created data. Also of use if you want to mask out given values (rather than randomly selecting indices), is to use np.where(condition, thing to do if true, thing to do if false)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "16f5330d-a509-453e-abca-97ff61ab4847",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                name                                            address   \n",
      "1          James Ray  1387 Natasha Land Suite 427\\nHarpermouth, WI 8...  \\\n",
      "2      Natasha Wells  838 Kevin Orchard Suite 111\\nPort Amber, RI 39191   \n",
      "3  Christina Jenkins            581 Taylor Oval\\nZacharyville, NE 98594   \n",
      "4    Hector Martinez  496 Gray Center Apt. 415\\nEast Staceyside, FM ...   \n",
      "5         Shawn Reid               562 Felicia Key\\nJamestown, UT 72079   \n",
      "\n",
      "   birth_date    education_level  \n",
      "1  2000-05-10  Bachelor's Degree  \n",
      "2  2006-04-12  Bachelor's Degree  \n",
      "3  2004-01-27    Master's Degree  \n",
      "4  2000-02-19  Bachelor's Degree  \n",
      "5  2003-02-23    Master's Degree  \n"
     ]
    }
   ],
   "source": [
    "# Number of samples\n",
    "n = 1000\n",
    "\n",
    "fake = Faker()\n",
    "\n",
    "# Generate random employee names (Nominal) without duplicates\n",
    "\n",
    "#first_names = [\"Brooklyn\",\"Alice\", \"Gerardo\", \"Deema\", \"Charlie\", \"Jaxon\", \"Mayar\", \"Noura\", \"Grace\", \"Mira\", \"Ian\", \"Yazan\", \"leif\",\"Efren\", \"Cristal\", \"Emerald\", \"Annie\", \"Jaela\", \"Anjelica\", \"Khalid\"]\n",
    "#last_names = [\"Smith\", \"Spence\" \"Afaneh\", \"Witte\", \"Brown\", \"Mosmar\", \"Horner\" \"Mizel\", \"Judge\", \"Martinez\", \"Robinson\", \"Nusair\", \"Wilson\", \"Young\", \"noble\",\"law\",\"crenshaw\", \"goebel\", \"barr\", \"pfeifer\"]\n",
    "\n",
    "# while len(writer_names) < n:\n",
    "#    full_name = f\"{random.choice(first_names)} {random.choice(last_names)}\"\n",
    "#    if full_name not in unique_names:\n",
    "#        writer_names.append(full_name) \n",
    "\n",
    "unique_names = set()\n",
    "\n",
    "while len(unique_names) < 1000:\n",
    "    unique_names.add(fake.name())\n",
    "\n",
    "# Convert the set to a list if needed\n",
    "writer_names = list(unique_names)\n",
    "\n",
    "# Generate random employment dates (Interval)\n",
    "birth_year = np.random.randint(1950, 2000, n)\n",
    "birth_month = np.random.randint(1,13,n)\n",
    "birth_day = np.random.randint(1,29,n)\n",
    "birth_date = [f'{joining_year[i]}-{str(joining_month[i]).zfill(2)}-'\n",
    "                     f'{str(joining_day[i]).zfill(2)}' for i in range(n)]\n",
    "\n",
    "# Generate Education Levels (Ordinal Data) with assigned weights\n",
    "education_levels = [\"Diploma\", \"Bachelor's Degree\", \"Master's Degree\", \"Ph.D.\"]\n",
    "e_weights = [0.10, 0.40, 0.30, 0.20]  \n",
    "education_data = np.random.choice(education_levels, n, p=e_weights)\n",
    "        \n",
    "# Generate book names\n",
    "address = [fake.address() for _ in range(n)]\n",
    "\n",
    "employees = pd.DataFrame({\n",
    "    'name': writer_names,\n",
    "    'address': address,\n",
    "    'birth_date': birth_date,\n",
    "    'education_level':education_data\n",
    "})\n",
    "\n",
    "employees.index = np.arange(1,len(df)+1)\n",
    "print(employees.head())\n",
    "\n",
    "# Information of Writers\n",
    "df_employees = employees[['name', 'address', 'birth_date', 'education_level']]\n",
    "\n",
    "# Save to CSV file\n",
    "df_employees.to_csv('writers.csv',header = True,index = True, index_label = 'id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "4de0d7bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 name\n",
      "1             Mystery\n",
      "2     Science Fiction\n",
      "3             Fantasy\n",
      "4             Romance\n",
      "5            Thriller\n",
      "6  Historical Fiction\n",
      "7         Non-Fiction\n"
     ]
    }
   ],
   "source": [
    "# Generate Genre Data (Nominal)\n",
    "genres = ['Mystery', 'Science Fiction', 'Fantasy', 'Romance', 'Thriller', 'Historical Fiction', 'Non-Fiction']\n",
    "\n",
    "# Data for Genres table\n",
    "genres = pd.DataFrame({\n",
    "    'name': genres,\n",
    "})\n",
    "\n",
    "genres.index = np.arange(1,len(genres)+1)\n",
    "print(genres)\n",
    "\n",
    "# Information on Genres\n",
    "df_genres = genres[['name']]\n",
    "\n",
    "# Save to CSV file\n",
    "df_genres.to_csv('genres.csv', header=True, index=True, index_label='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "6ccdc335",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   writer_id                                       name publish_date   \n",
      "1        968  Vision-oriented disintermediate emulation   1978-02-28  \\\n",
      "2        472    Triple-buffered zero tolerance alliance   2013-12-12   \n",
      "3        983        Profound asymmetric instruction set   1986-08-09   \n",
      "4        666      Managed cohesive budgetary management   1989-12-05   \n",
      "5        631                 Secured methodical product   2008-04-12   \n",
      "\n",
      "        price                                        description  \n",
      "1  129.485541  White by expert hotel those usually reason. Vo...  \n",
      "2   93.563595  Glass event improve kind each improve. Languag...  \n",
      "3  207.899788  Boy opportunity important ok. Maintain if deve...  \n",
      "4  146.784733  Mr member game mention experience affect here....  \n",
      "5         NaN  Do town ask surface another strong million. We...  \n"
     ]
    }
   ],
   "source": [
    "# Generate book names\n",
    "book_names = [fake.catch_phrase() for _ in range(2000)]\n",
    "\n",
    "# Generate books publish date\n",
    "publish_dates = [fake.date() for _ in range(2000)]\n",
    "\n",
    "# Ratio data: Price of book\n",
    "prices = np.random.lognormal(mean=5, sigma=0.5, size=2000).astype(float)\n",
    "\n",
    "# Introduce null values (e.g., replace 5% of the values with None)\n",
    "null_percentage = 5\n",
    "num_nulls = int(len(prices) * (null_percentage / 100))\n",
    "indices_to_nullify = np.random.choice(len(prices), num_nulls, replace=False)\n",
    "\n",
    "price_with_nulls = prices.copy()\n",
    "price_with_nulls[indices_to_nullify] = np.nan\n",
    "\n",
    "random_descriptions = [fake.text() for _ in range(2000)]\n",
    "\n",
    "books = pd.DataFrame({\n",
    "    'writer_id': np.random.randint(1, 1001, size=2000),\n",
    "    'name': book_names,\n",
    "    'publish_date': publish_dates,\n",
    "    'price': price_with_nulls,\n",
    "    'description': random_descriptions\n",
    "})\n",
    "\n",
    "books.index = np.arange(1,len(books)+1)\n",
    "print(books.head())\n",
    "\n",
    "# Information of Books\n",
    "df_books = books[['writer_id','name', 'publish_date', 'price', 'description']]\n",
    "\n",
    "# Save to CSV file\n",
    "df_books.to_csv('books.csv', header=True, index=True, index_label='id')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83dc029a-730d-4825-91a4-843a2bb2fc8b",
   "metadata": {},
   "source": [
    "It is helpful to set as your dataframe index, the primary key of the database, as this is by default saved to the output csv. Note that this can be a compound key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "80380119",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[688 504 429 ... 828 504 272]\n",
      "   book_id  genre_id\n",
      "1      890         4\n",
      "2      995         6\n",
      "3      741         2\n",
      "4      454         3\n",
      "5      718         6\n"
     ]
    }
   ],
   "source": [
    "print(np.random.randint(1, 1001, size=2000),)\n",
    "\n",
    "books_genre = pd.DataFrame({\n",
    "    'book_id': np.random.randint(1, 1001, size=2000),\n",
    "    'genre_id': np.random.randint(1, 8, size=2000)\n",
    "})\n",
    "\n",
    "\n",
    "books_genre.index = np.arange(1,len(books_genre)+1)\n",
    "print(books_genre.head())\n",
    "\n",
    "# Information of Books\n",
    "df_books = books_genre[['book_id', 'genre_id']]\n",
    "\n",
    "# Save to CSV file\n",
    "df_books.to_csv('books_genre.csv', header=True, index=True, index_label='id')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "940f51d2-66d3-426b-b134-6e5a2b93568c",
   "metadata": {},
   "source": [
    "Okay, now for splitting a pandas dataframe into multiple csvs, we need to select different columns at once.\n",
    "To do so, pass a list of column names to the dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24c30ccf-4119-4a93-b9f0-00e3c0565aa5",
   "metadata": {},
   "source": [
    "The tables to be saved depend upon what columns you have created."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "661f3cfc-3d62-4eb2-aa04-986e5265201b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Outputting csvs to SQLite\n",
    "- Open SQLite Browser\n",
    "- New database, save as house_database.db\n",
    "- Ensure you are on the database structure tab\n",
    "- File > Import > Table from CSV file\n",
    "- Check the preview looks as expected then confirm the import\n",
    "- Write changes (if you skip this, it will prompt you on the next step)\n",
    "- Right click on the new table then modify table\n",
    "- Check the boxes as appropriate, Primary Key, Not Null, Auto Increment, Unique\n",
    "- On some tables, scroll along to the right and click on the foreign key section, and assign the relation/attribute"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa631696-a984-497b-ba66-c15acf56b98b",
   "metadata": {},
   "source": [
    "Once all of this is complete, perform any JOIN transaction under the Execute SQL tab.\n",
    "From that join, use the SQLite plotting functionality to make a basic scatter plot."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9483db3-0c22-4cfd-8e5b-6d1a8e605532",
   "metadata": {},
   "source": [
    "Upload the image from your scatter plot (there is a button to save the image) to this notebook below:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c70ade3-6d70-4d3c-90f5-d5c49ae4bf6d",
   "metadata": {},
   "source": [
    "![title](yourimage.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
